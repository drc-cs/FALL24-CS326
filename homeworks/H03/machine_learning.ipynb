{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H.03 | Penguins\n",
    "\n",
    "We'll revisit our penguin friends for H.03. Over the course of this homework assignment, you will be asked to train a number of classification and regression models to predict the species of a penguin and the body mass of a penguin. We will utilize the NumPy, Pandas, and Scikit-Learn libraries to accomplish this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "# Read in data and drop rows with missing values.\n",
    "DATASET_URL = \"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/main/inst/extdata/penguins.csv\"\n",
    "df = pd.read_csv(DATASET_URL)\n",
    "df = df.dropna()\n",
    "\n",
    "# Select columns that we want to use.\n",
    "df = df[[\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\", \"species\"]]\n",
    "\n",
    "# Drop rows with species \"Gentoo\" to make the dataset binary (Adelie vs Chinstrap).\n",
    "df = df.query(\"species != 'Gentoo'\")\n",
    "\n",
    "# Display the first few rows of the dataset.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `X` and `y`\n",
    "\n",
    "Recall that in supervised learning, we have a dataset consisting of both input features and output labels. The goal is to learn a model that can predict the output labels (y) from the input features (X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a feature matrix.\n",
    "feature_df = df.drop(columns=[\"species\"]).values\n",
    "\n",
    "# Create a label vector.\n",
    "species_labels = df[\"species\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarize the Target\n",
    "\n",
    "We will begin by binarizing the target variable. The targets include a \"Chinstrap\" and \"Adelie\" class. We will create a new target variable that is 1 if the penguin is a \"Chinstrap\" and 0 if the penguin is an \"Adelie\". Please write a function `binarize` in machine_learning.py that takes in a list of species and returns a list of 1s and 0s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from machine_learning import binarize\n",
    "\n",
    "# Binarize the labels.\n",
    "binarized_labels = binarize(species_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data\n",
    "\n",
    "We will begin by loading the Palmer Penguins dataset and splitting it into a training set and a testing set. We will not use a validation set in this homework assignment, because we don't need to tune any hyperparameters. We will use the training set to train our models and the testing set to evaluate our models.\n",
    "\n",
    "Please write a function `split_data` using the instructions in machine_learning.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from machine_learning import split_data\n",
    "\n",
    "x_train, x_test, y_train, y_test = split_data(feature_df, binarized_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize x_train and x_test.\n",
    "\n",
    "Please implement standard scaling to standardize the feature dataframe. Recall that standard scaling is defined as:\n",
    "\n",
    "$$ x_{\\text{standardized}} = \\frac{x - \\mu}{\\sigma} $$\n",
    "\n",
    "where $\\mu$ is the mean of the feature and $\\sigma$ is the standard deviation of the feature. Please write a function `standardize_training_data` that takes in a training set and a testing set and returns the standardized training set and testing set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from machine_learning import standardize\n",
    "\n",
    "x_train, x_test = standardize(x_train, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN\n",
    "\n",
    "Now that we have a standardized `X` and binarized `y`, let's implement our first model. We will use the K-Nearest Neighbors algorithm to predict the species of a penguin. We will use the training set to train the model and the testing set to evaluate the model.\n",
    "\n",
    "You will be asked to implement the following common distance metrics:\n",
    "\n",
    "1. `euclidean_distance`\n",
    "2. `cosine_distance`\n",
    "\n",
    "And implement a brute-force K-Nearest Neighbors algorithm:\n",
    "\n",
    "3. `knn`\n",
    "\n",
    "Please see more details in machine_learning.py. You may only use the numpy library. You **may not** use the scikit-learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from machine_learning import knn, euclidean_distance, cosine_distance\n",
    "\n",
    "euclidean_y_pred = [knn(x = x_train, y = y_train, sample = x_test_sample, distance_method = euclidean_distance, k = 3) for x_test_sample in x_test]\n",
    "cosine_y_pred = [knn(x = x_train, y = y_train, sample = x_test_sample, distance_method = cosine_distance, k = 2) for x_test_sample in x_test]\n",
    "\n",
    "print(\"Euclidean Distance Classification Report\")\n",
    "print(classification_report(y_test, euclidean_y_pred, target_names=[\"Adelie\", \"Chinstrap\"]))\n",
    "\n",
    "print(\"Cosine Distance Classification Report\")\n",
    "print(classification_report(y_test, cosine_y_pred, target_names=[\"Adelie\", \"Chinstrap\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "Let's implement our second model. We will use linear regression to predict the body_mass_g of a given penguin.\n",
    "\n",
    "You will be asked to implement the following functions:\n",
    "\n",
    "1. `linear_regression`\n",
    "\n",
    "Recall the equation for the normal equation:\n",
    "\n",
    "$$ \\theta = (X^T X)^{-1} X^T y $$\n",
    "\n",
    "2. `linear_regression_predict`\n",
    "\n",
    "Recall the equation for linear regression:\n",
    "\n",
    "$$ \\hat{y} = X \\theta $$\n",
    "\n",
    "3. `mean_squared_error`\n",
    "\n",
    "Recall the equation for the mean squared error:\n",
    "$$ \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $$\n",
    "\n",
    "Please see more details in machine_learning.py. You may only use the numpy library. You **may not** use the scikit-learn library.\n",
    "\n",
    "### First Pass\n",
    "\n",
    "In our first pass of the model, let's quantify our performance when using only the flipper_length_mm feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from machine_learning import linear_regression, linear_regression_predict, mean_squared_error\n",
    "\n",
    "flipper_length_train = x_train[:, -2] # flipper_length_mm\n",
    "body_mass_train = x_train[:, -1] # body_mass_g\n",
    "\n",
    "flipper_length_test = x_test[:, -2] # flipper_length_mm\n",
    "body_mass_test = x_test[:, -1] # body_mass_g\n",
    "\n",
    "linear_regression_weights = linear_regression(flipper_length_train.reshape(-1, 1), body_mass_train)\n",
    "body_mass_pred = linear_regression_predict(flipper_length_test.reshape(-1, 1), linear_regression_weights)\n",
    "\n",
    "mse = mean_squared_error(body_mass_test, body_mass_pred)\n",
    "\n",
    "print(\"Mean Squared Error (only using flipper length):\", round(mse, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of First Pass\n",
    "\n",
    "It is always a good idea to visualize our results. You don't have to do anything here. You can see that our model is doing a fine job of finding the best possible slope when only using one feature, but there is a lot of unnaccounted-for variance! In the second pass, we'll use all the features to predict the body mass of a penguin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot demonstrating the linear regression model.\n",
    "fig = px.scatter(x=flipper_length_train, y=body_mass_train, template = \"plotly_white\", title = \"Regression\")\n",
    "\n",
    "# plot the regression line.\n",
    "x_line = np.linspace(flipper_length_train.min(), flipper_length_train.max(), 100)\n",
    "y_line = linear_regression_weights[1] * x_line + linear_regression_weights[0]\n",
    "fig.add_scatter(x=x_line, y=y_line, mode=\"lines\", name=\"Regression Line\", line=dict(color=\"red\", dash=\"dash\"))\n",
    "\n",
    "# plot each test sample.\n",
    "fig.add_scatter(x=flipper_length_test, y=body_mass_test, mode=\"markers\", name=\"Test Samples\", marker=dict(size=10, color=\"grey\"))\n",
    "\n",
    "# plot each predicted test sample.\n",
    "fig.add_scatter(x=flipper_length_test, y=body_mass_pred, mode=\"markers\", name=\"Predicted Test Samples\", marker=dict(size=10, color=\"red\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Pass\n",
    "\n",
    "Our first pass wasn't so bad! But we can probably do better. Now, we'll include all of the remaining features (bill_length_mm, bill_depth_mm) in our model. You will see a lower mean squared error when using all the features. Pause for a moment and consider what that means!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from machine_learning import linear_regression, linear_regression_predict, mean_squared_error\n",
    "\n",
    "flipper_length_train = x_train[:, :-1] # bill_length_mm, bill_depth_mm, flipper_length_mm\n",
    "body_mass_train = x_train[:, -1] # body_mass_g\n",
    "\n",
    "flipper_length_test = x_test[:, :-1] # flipper_length_mm\n",
    "body_mass_test = x_test[:, -1] # body_mass_g\n",
    "\n",
    "linear_regression_weights = linear_regression(flipper_length_train, body_mass_train)\n",
    "body_mass_pred = linear_regression_predict(flipper_length_test, linear_regression_weights)\n",
    "mse = mean_squared_error(body_mass_test, body_mass_pred)\n",
    "\n",
    "print(\"Mean Squared Error (using flipper length, bill length, and bill depth):\", round(mse, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Let's implement our third model. We will use logistic regression to predict the species of a penguin. We will use the training set to train the model and the testing set to evaluate the model.\n",
    "\n",
    "You will be asked to implement the following functions:\n",
    "\n",
    "1. `logistic_regression_gradient_descent`\n",
    "\n",
    "Recall the equation for the gradient of the cost function:\n",
    "\n",
    "$$ \\nabla J(\\theta) = \\frac{1}{m} X^T (h_{\\theta}(X) - y) $$\n",
    "\n",
    "where $h_{\\theta}(X)$ is the sigmoid function:\n",
    "\n",
    "$$ h_{\\theta}(X) = \\sigma(X \\theta) $$\n",
    "\n",
    "2. `logistic_regression_predict`\n",
    "\n",
    "Recall the equation for logistic regression:\n",
    "\n",
    "$$ \\hat{y} = \\sigma(X \\theta) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from machine_learning import logistic_regression_gradient_descent, logistic_regression_predict\n",
    "\n",
    "weights = logistic_regression_gradient_descent(x_train, y_train)\n",
    "y_pred_probabiltiies = logistic_regression_predict(x_test, weights)\n",
    "y_pred = np.round(y_pred_probabiltiies)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Adelie\", \"Chinstrap\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the predictions for plotting purposes.\n",
    "sorted_indices = np.argsort(y_pred_probabiltiies)\n",
    "predictions = y_pred_probabiltiies[sorted_indices]\n",
    "labels = y_test[sorted_indices]\n",
    "\n",
    "fig = px.scatter(y = predictions, x = list(range(len(predictions))), title = \"Predicted Probabilities (Sorted)\", labels = {\"y\": \"Probability\"}, template = \"plotly_white\")\n",
    "fig.add_scatter(y = labels, x = list(range(len(labels))), mode = \"markers\", name = \"True Labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs326",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
